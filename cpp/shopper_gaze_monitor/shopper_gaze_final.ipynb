{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shopper Gaze Monitor\n",
    "\n",
    "This shopper gaze monitor application is one of a series of reference implementations for Computer Vision (CV) using the Intel® Distribution of OpenVINO™ toolkit. It is designed for a retail shelf mounted camera system that counts the number of passers-by that look towards the display vs. the number of people that pass by the display without looking. It is intended to provide real-world marketing statistics for in-store shelf-space advertising.\n",
    "\n",
    "# How it works\n",
    "\n",
    "The application uses a video source, such as a camera, to grab frames, and then uses 2 different Deep Neural Networks (DNNs) to process the data. The first neural network detect faces. If the person's face is detected, it is counted as a \"shopper\".\n",
    "\n",
    "A second neural network is then used to determine the head pose detection for each detected face. If the person's head is facing towards the camera, it is counted as a \"looker\".\n",
    "\n",
    "The data can then optionally be sent to a MQTT machine to machine messaging server, as part of a retail data analytics system.\n",
    "\n",
    "The DNN models can be downloaded using ./downloader.py present in model downloader folder that is part of the Intel® Distribution of OpenVINO™ toolkit.\n",
    "\n",
    "\n",
    "The program creates three threads for concurrency:\n",
    "\n",
    " ->main thread that performs the video i/o\n",
    " ->worker thread that processes video frames using the deep neural networks\n",
    " ->worker thread that publishes any MQTT messages\n",
    " \n",
    " \n",
    " ## Step 0: Set Up\n",
    " \n",
    " ### 0.1: Import dependencies\n",
    "    \n",
    "Run the below cell to import Python dependencies needed for displaying the results in this notebook (tip: select the cell and use Ctrl+enter to run the cell)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path().resolve().parent.parent))\n",
    "from demoTools.demoutils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the code\n",
    "\n",
    "Start by changing the current directory to wherever you have the application code and build it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rm -rf build && mkdir build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/u33139/DEVC_17_dec23/iot-devcloud/cpp/shopper_gaze_monitor/build\n"
     ]
    }
   ],
   "source": [
    "cd build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!cmake .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above produces an executable monitor. This executable takes in a number of different command line arguments.\n",
    "\n",
    "Run the following cell to see the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting main\n",
      "After Commandline parser\n",
      "Arg count:2\n",
      "Use this script to using OpenVINO.\n",
      "Usage: monitor [params] \n",
      "\n",
      "\t-d, --device\n",
      "\t\tDevice to run the inference (CPU, GPU, MYRIAD, FPGA or HDDL only).\n",
      "\t-f, --flag\n",
      "\t\tflag to run on sync or async mode.\n",
      "\t-h, --help (value:true)\n",
      "\t\tPrint help message.\n",
      "\t-i, --input\n",
      "\t\tPath to input image or video file.\n",
      "\t-m, --model\n",
      "\t\tPath to .xml file of model containing face recognizer.\n",
      "\t-o, --output\n",
      "\t\tPath to output file.\n",
      "\t--pm, --posemodel\n",
      "\t\tPath to .xml file of face pose model.\n",
      "\t-r, --rate (value:1)\n",
      "\t\tnumber of seconds between data updates to MQTT server.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./monitor -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The version of the cpp file here is a slightly modified version of the shopper gaze monitor code built-in to the the Intel® Distribution of OpenVINO™ toolkit. In this version, the result is written into a output mp4 file specified by the -o flag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: using OpenVINO\n",
    "\n",
    "## Downloading IR Model\n",
    "\n",
    "The Intel® Distribution of OpenVINO™ toolkit comes with model downloader that can download pre-compiled Intermediate Representation (IR) models that are optimized for different end-point target devices. These models can be created from existing DNN models from popular frameworks (e.g. Caffe*, TF) using the Model Optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "!/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --print_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the '!' is a special Jupyter Notebook command that allows you to run shell commands as if you are in a commannd line. So the above command will work straight out of the box on in a terminal (with '!' removed).\n",
    "\n",
    "In this demo we will be using the 4 different types of models, with two model files each for FP16 and FP32. These models can be downloaded with the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name face-detection-adas-0001 -o models\n",
    "!/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name face-detection-adas-0001-fp16 -o models\n",
    "!/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name head-pose-estimation-adas-0001 -o models\n",
    "!/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name head-pose-estimation-adas-0001-fp16 -o models\n",
    "!/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name age-gender-recognition-retail-0013 -o models\n",
    "!/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name age-gender-recognition-retail-0013-fp16 -o models\n",
    "!/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name emotions-recognition-retail-0003 -o models\n",
    "!/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name emotions-recognition-retail-0003-fp16 -o models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input arguments are as follows:\n",
    "\n",
    "--name : name of the model you want to download. It should be one of the models listed in the previous cell.\n",
    "-o : output directory. If this directory does not exist, it will be created.\n",
    "There are more arguments to this script and you can get the full list using the -h option.\n",
    "\n",
    "Running the inference\n",
    "Now we are ready to run the inference workload. In this step, we will be submitting the workload as a job to the job queue.\n",
    "\n",
    "## Step 2. Running the Inference\n",
    "\n",
    "Currently, you are on what is called a \"devnode\". On this system, you are allocated just one core on a large Intel® Xeon® CPU. The purpose of this node is to develop code on the devnode and run minimal sections of Jupyter* Notebooks, but it is not meant to compute intensive jobs like deep learning inference. So we need to request additional resources from the cluster of Edge nodes to run the inference and this is done through the job queue.\n",
    "\n",
    "To put an item on the job queue, we must first create a bash script that run the workload we want. Run the following cell to create bash script shopper_gaze.sh which will be our job script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting shopper_gaze.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile shopper_gaze.sh\n",
    "#PBS\n",
    "INPUT_FILE=$1\n",
    "OUTPUT_FILE=$2\n",
    "FP_MODEL=$3\n",
    "BACKEND=$4\n",
    "#0: CPU target (by default), 1: OpenCL, 2: OpenCL fp16 (half-float precision), 3: VPU,5: HETERO:FPGA,CPU\n",
    "TARGET=$5\n",
    "\n",
    "\n",
    "if [ \"$TARGET\" == \"5\" ]; then\n",
    "    # Environment variables and compilation for edge compute nodes with FPGAs\n",
    "    source /opt/intel/init_openvino.sh\n",
    "    aocl program acl0 /opt/intel/openvino/bitstreams/a10_vision_design_sg1_bitstreams/2019R3_PV_PL1_FP16_MobileNet_Clamp.aocx\n",
    "fi\n",
    "\n",
    "cd $PBS_O_WORKDIR\n",
    "export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/opt/intel/openvino/deployment_tools/inference_engine/lib/intel64/\n",
    "\n",
    " \n",
    "if [ \"$FP_MODEL\" == \"FP16\" ]; then\n",
    "  FPEXT='-fp16'\n",
    "fi\n",
    "\n",
    "    \n",
    "./monitor \\\n",
    "-m=\"/home/u33139/DEVC_17_dec23/iot-devcloud/cpp/shopper_gaze_monitor/build/models/intel/face-detection-adas-0001/FP32/face-detection-adas-0001.xml\" \\\n",
    "-pm=\"/home/u33139/DEVC_17_dec23/iot-devcloud/cpp/shopper_gaze_monitor/build/models/intel/head-pose-estimation-adas-0001/FP32/head-pose-estimation-adas-0001.xml\" \\\n",
    "-i=\"/home/u33139/DEVC_17_dec23/iot-devcloud/cpp/shopper_gaze_monitor/resources/face-demographics-walking-and-pause.mp4\" \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To put this script on the job queue, we use the command qsub. There are two important arguments we use with this command.\n",
    "\n",
    "First, the -l flag. This flag is used to specify what type of resources to request from the cluster. For example this can be used to request an Intel® Xeon® CPU based system, or it can be used to request a system with an FPGA accelerator card in it. The syntax is -l nodes=1:<tag> where <tag> is the descriptor tag for the resource you want. For example, -l nodes=1:tank-870:e3-1268l-v5 will request an Intel® Xeon® system. To see the list of available tags, and the number of avilable systems, run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     35      properties = idc001skl,compnode,iei,tank-870,intel-core,i5-6500te,skylake,intel-hd-530,ram8gb,net1gbe\r\n",
      "     15      properties = idc002mx8,compnode,iei,tank-870,intel-core,i5-6500te,skylake,intel-hd-530,ram8gb,net1gbe,hddl-r,iei-mustang-v100-mx8\r\n",
      "     17      properties = idc003a10,compnode,iei,tank-870,intel-core,i5-6500te,skylake,intel-hd-530,ram8gb,net1gbe,hddl-f,iei-mustang-f100-a10\r\n",
      "     23      properties = idc004nc2,compnode,iei,tank-870,intel-core,i5-6500te,skylake,intel-hd-530,ram8gb,net1gbe,ncs,intel-ncs2\r\n",
      "      6      properties = idc006kbl,compnode,iei,tank-870,intel-core,i5-7500t,kaby-lake,intel-hd-630,ram8gb,net1gbe\r\n",
      "     13      properties = idc007xv5,compnode,iei,tank-870,intel-xeon,e3-1268l-v5,skylake,intel-hd-p530,ram32gb,net1gbe\r\n",
      "     15      properties = idc008u2g,compnode,up-squared,grove,intel-atom,e3950,apollo-lake,intel-hd-505,ram4gb,net1gbe,ncs,intel-ncs2\r\n",
      "      1      properties = idc009jkl,compnode,jwip,intel-core,i5-7500,kaby-lake,intel-hd-630,ram8gb,net1gbe\r\n",
      "      1      properties = idc010jal,compnode,jwip,intel-atom,e3950,apollo-lake,intel-hd-505,ram4gb,net1gbe\r\n",
      "      1      properties = idc011ark2250s,compnode,advantech,intel-core,i5-6442eq,skylake,intel-hd-503,ram8gb,net1gbe\r\n",
      "      1      properties = idc012ark1220l,compnode,advantech,intel-atom,e3940,apollo-lake,intel-hd-500,ram4gb,net1gbe\r\n",
      "      1      properties = idc013ds580,compnode,advantech,intel-atom,e3950,apollo-lake,intel-hd-505,ram2gb,net1gbe\r\n",
      "      1      properties = idc101agg,compnode,iei,tank-870,intel-core,i5-7500t,kaby-lake,intel-hd-630,ram8gb,net1gbe\r\n",
      "      1      properties = idc101col,compnode,iei,tank-870,intel-core,i5-7500t,kaby-lake,intel-hd-630,ram8gb,net1gbe\r\n",
      "      1      properties = idc101rdk,compnode,iei,tank-870,intel-core,i5-6500te,skylake,intel-hd-530,ram8gb,net1gbe,ncs,intel-ncs2\r\n",
      "      2      properties = idc101ros,compnode,iei,tank-870,intel-core,i5-7500t,kaby-lake,intel-hd-630,ram8gb,net1gbe\r\n",
      "      3      properties = idc101xv5,compnode,iei,tank-870,intel-xeon,e3-1268l-v5,skylake,intel-hd-p530,ram32gb,net1gbe\r\n"
     ]
    }
   ],
   "source": [
    "!pbsnodes | grep compnode | sort | uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then there is the -F flag, which is used to pass in arguments to the job script. The face_detection_demo.sh takes in 2 arguments: 1) the path to the video to run inference on. 2) targeted device (CPU,GPU,MYRIAD). The job scheduler will use the contents of -F flag as the argument to the job script.\n",
    "\n",
    "The following line will request an Intel Xeon system, and passes in \"faces-recognition-walking.mp4 CPU\" to the job script. Run the cell to submit this job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"VIDEO\"] = \"../resources/face-demographics-walking-and-pause.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submitting to an edge compute node with an Intel® Core™ CPU\n",
    "\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank 870-Q170</a> edge node with an <a \n",
    "    href=\"https://ark.intel.com/products/88186/Intel-Core-i5-6500TE-Processor-6M-Cache-up-to-3-30-GHz-\">Intel \n",
    "    Core i5-6500TE</a>. The inference workload will run on the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting job to Intel Core CPU...\n",
      "9700.v-qsvr-1.devcloud-edge\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "538d64b0b6ea4223a58020e41a5158a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Inference', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Submitting job to Intel Core CPU...\")\n",
    "#Submit job to the queue\n",
    "job_id_core = !qsub shopper_gaze.sh -l nodes=1:tank-870:i5-6500te -F \"$VIDEO ../results/ FP32 CPU 0\"\n",
    "print(job_id_core[0])\n",
    "\n",
    "#Progress indicators\n",
    "if job_id_core:\n",
    "    progressIndicator('../results/', 'i_progress_'+job_id_core[0]+'.txt', \"Inference\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submitting to an edge compute node with Intel® Xeon® CPU\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank* 870-Q170</a> edge node with an <a \n",
    "    href=\"https://ark.intel.com/products/88178/Intel-Xeon-Processor-E3-1268L-v5-8M-Cache-2-40-GHz-\">Intel® \n",
    "    Xeon® Processor E3-1268L v5</a>. The inference workload will run on the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Submitting job to Intel Xeon CPU...\")\n",
    "#Submit job to the queue\n",
    "job_id_xeon = !qsub shopper_gaze.sh -l nodes=1:tank-870:e3-1268l-v5 -F \"$VIDEO ../results/ FP32 2 0\"\n",
    "print(job_id_xeon[0]) \n",
    "#Progress indicators\n",
    "if job_id_xeon:\n",
    "    progressIndicator('../results/', 'i_progress_'+job_id_xeon[0]+'.txt', \"Inference\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submitting to an edge compute node with Intel® Core™ CPU and using the onboard Intel GPU\n",
    "\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank 870-Q170</a> edge node with an <a href=\"https://ark.intel.com/products/88186/Intel-Core-i5-6500TE-Processor-6M-Cache-up-to-3-30-GHz-\">Intel Core i5-6500TE</a>. The inference workload will run on the Intel® HD Graphics 530 card integrated with the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Submitting job to Intel Core CPU with Intel GPU... FP32\")\n",
    "#Submit job to the queue\n",
    "job_id_gpu = !qsub shopper_gaze.sh -l nodes=1:tank-870:i5-6500te -F \"$VIDEO ../results/ FP16 2 1\"\n",
    "print(job_id_gpu[0])\n",
    "\n",
    "#Progress indicators\n",
    "if job_id_gpu:\n",
    "    progressIndicator('../results/', 'i_progress_'+job_id_gpu[0]+'.txt', \"Inference\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submitting to an edge compute node with Intel® VPU\n",
    "\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank 870-Q170</a> edge node with an <a href=\"https://ark.intel.com/products/88186/Intel-Core-i5-6500TE-Processor-6M-Cache-up-to-3-30-GHz-\">Intel Core™ i5-6500te CPU</a> . The inference workload will run on the <a href=\"https://www.ieiworld.com/mustang-v100/en/\"> IEI Mustang-V100-MX8 </a> card installed in this node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Submitting job to node with Intel VPU...\")\n",
    "#Submit job to the queue\n",
    "job_id_hddl_fp16 = !qsub shopper_gaze.sh -l nodes=1:tank-870:iei-mustang-v100-mx8 -F \"$VIDEO ../results/ FP16 2 3\"\n",
    "print(job_id_hddl_fp16[0]) \n",
    "#Progress indicators\n",
    "if job_id_hddl_fp16:\n",
    "    progressIndicator('../results/', 'i_progress_'+job_id_hddl_fp16[0]+'.txt', \"Inference\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submitting to an edge compute node with IEI Mustang-F100-A10 (Intel® Arria® 10 FPGA)¶\n",
    "\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank 870-Q170</a> edge node with an <a href=\"https://ark.intel.com/products/88186/Intel-Core-i5-6500TE-Processor-6M-Cache-up-to-3-30-GHz-\">Intel Core i5-6500te CPU</a> . The inference workload will run on the <a href=\"https://www.ieiworld.com/mustang-f100/en/\"> IEI Mustang-F100-A10 </a> card installed in this node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Submitting job to node with Intel FPGA HDDL-F...\")\n",
    "#Submit job to the queue\n",
    "job_id_fpga = !qsub shopper_gaze.sh -l nodes=1:tank-870:i5-6500te:iei-mustang-f100-a10 -F \"$VIDEO ../results/ FP32 2 5\"\n",
    "print(job_id_fpga[0])\n",
    "\n",
    "#Progress indicators\n",
    "if job_id_fpga:\n",
    "    progressIndicator('../results/', 'i_progress_'+job_id_fpga[0]+'.txt', \"Inference\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submitting to an edge compute node with Intel® Movidius™ Neural Compute Stick 2\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank 870-Q170</a> edge node with an <a href=\"https://ark.intel.com/products/88186/Intel-Core-i5-6500TE-Processor-6M-Cache-up-to-3-30-GHz-\">Intel Core i5-6500te CPU</a>. The inference workload will run on an <a \n",
    "    href=\"https://software.intel.com/en-us/neural-compute-stick\">Intel Neural Compute Stick 2</a> installed in this  node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Submitting job to node with Intel NCS2...\")\n",
    "#Submit job to the queue\n",
    "job_id_ncs2 = !qsub shopper_gaze.sh -l nodes=1:tank-870:i5-6500te:intel-ncs2 -F \"$VIDEO ../results/ FP16 2 3\"\n",
    "print(job_id_ncs2[0])\n",
    "\n",
    "#Progress indicators\n",
    "if job_id_ncs2:\n",
    "    progressIndicator('../results/', 'i_progress_'+job_id_ncs2[0]+'.txt', \"Inference\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submitting to an edge compute node with UP Squared Grove IoT Development Kit (UP2)\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/up-squared-grove-dev-kit\">UP Squared Grove IoT Development Kit</a> edge node with an <a \n",
    "    href=\"https://ark.intel.com/products/96488/Intel-Atom-x7-E3950-Processor-2M-Cache-up-to-2-00-GHz-\">Intel Atom® x7-E3950 Processor</a>. The inference  workload will run on the integrated Intel® HD Graphics 505 card."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Submit job to the queue\n",
    "job_id_up2 = !qsub shopper_gaze.sh -l nodes=1:up-squared -F \"$VIDEO ../results/ FP32 2 1\"\n",
    "print(job_id_up2[0]) \n",
    "#Progress indicators\n",
    "if job_id_up2:\n",
    "    progressIndicator('../results/', 'i_progress_'+job_id_up2[0]+'.txt', \"Inference\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if the jobs are done\n",
    "\n",
    "To check on the jobs that were submitted, use the `qstat` command.\n",
    "\n",
    "We have created a custom Jupyter widget  to get live qstat update.\n",
    "Run the following cell to bring it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "liveQstat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see the jobs that you have submitted (referenced by `Job ID` that gets displayed right after you submit the job in step 2.3).\n",
    "There should also be an extra job in the queue \"jupyterhub\": this job runs your current Jupyter Notebook session.\n",
    "\n",
    "The 'S' column shows the current status. \n",
    "- If it is in Q state, it is in the queue waiting for available resources. \n",
    "- If it is in R state, it is running. \n",
    "- If the job is no longer listed, it means it is completed.\n",
    "\n",
    "**Note**: Time spent in the queue depends on the number of users accessing the edge nodes. Once these jobs begin to run, they should take from 1 to 5 minutes to complete. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Wait!***\n",
    "\n",
    "Please wait for the inference jobs and video rendering complete before proceeding to the next step.\n",
    "\n",
    "## Step 3: View Results\n",
    "\n",
    "Once the jobs are completed, the queue system outputs the stdout and stderr streams of each job into files with names of the form\n",
    "\n",
    "`obj_det_{type}.o{JobID}`\n",
    "\n",
    "`obj_det_{type}.e{JobID}`\n",
    "\n",
    "(here, obj_det_{type} corresponds to the `-N` option of qsub).\n",
    "\n",
    "However, for this case, we may be more interested in the output video files. They are stored in mp4 format inside the `results/` directory.\n",
    "We wrote a short utility script that will display these videos with in the notebook.\n",
    "Run the cells below to display them.\n",
    "See `demoutils.py` if you are interested in understanding further how the results are displayed in notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "videoHTML('IEI Tank Core (Intel Core CPU)',\n",
    "          ['results/output_'+job_id_core[0]+'.mp4'],\n",
    "          '../results/stats_'+job_id_core[0]+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoHTML('IEI Tank Core (Intel Xeon CPU)',\n",
    "          ['results/output_'+job_id_xeon[0]+'.mp4'],\n",
    "          '../results/stats_'+job_id_xeon[0]+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoHTML('IEI Intel GPU (Intel Core + Onboard GPU)', \n",
    "          ['results/output_'+job_id_gpu[0]+'.mp4'],\n",
    "          '../results/stats_'+job_id_gpu[0]+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "videoHTML('IEI Tank Core (Intel VPU - Mustang v100-mx8)',\n",
    "          ['results/output_'+job_id_hddl_fp16[0]+'.mp4'],\n",
    "          '../results/stats_'+job_id_hddl_fp16[0]+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoHTML('Tank-870:i5-6500te (Intel® NCS2)',\n",
    "          ['results/output_'+job_id_ncs2[0]+'.mp4'],\n",
    "          '../results/stats_'+job_id_ncs2[0]+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "videoHTML('IEI Tank + IEI Mustang-F100-A10 (Intel® Arria® 10 FPGA)',\n",
    "          ['results/output_'+job_id_fpga[0]+'.mp4'],\n",
    "          '../results/stats_'+job_id_fpga[0]+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoHTML('UP Squared Grove IoT Development Kit (UP2)',\n",
    "          ['results/output_'+job_id_up2[0]+'.mp4'],\n",
    "          '../results/stats_'+job_id_up2[0]+'.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Assess Performance\n",
    "\n",
    "The running time of each inference task is recorded in `results/*/stats.txt`, where the subdirectory name corresponds to the architecture of the target edge compute node. Run the cell below to plot the results of all jobs side-by-side. Lower values mean better performance. Keep in mind that some architectures are optimized for the highest performance, others for low power or other metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arch_list = [('core', 'Intel Core\\ni5-6500TE\\nCPU'),\n",
    "             ('xeon', 'Intel Xeon\\ne3-1268l-v5'),\n",
    "             ('gpu', ' Intel Core\\ni5-6500TE\\nGPU'),\n",
    "              ('fpga', 'Intel FPGA\\nMustang-\\nF100-A10'),\n",
    "             ('ncs2', 'Intel\\nNCS2'),\n",
    "            ('hddl_fp16', 'Intel VPU\\nMustang-\\nv100-mx8'),   \n",
    "            ('up2', 'Intel Atom\\nUP2/GPU')]\n",
    "\n",
    "stats_list = []\n",
    "for arch, a_name in arch_list:\n",
    "    if 'job_id_'+arch in vars():\n",
    "        #stats_list.append(('../results/{arch}/stats.txt'.format(arch=arch), a_name))\n",
    "        stats_list.append(('../results/stats_'+vars()['job_id_'+arch][0]+'.txt', a_name))\n",
    "    else:\n",
    "        stats_list.append(('placeholder'+arch, a_name))\n",
    "\n",
    "summaryPlot(stats_list, 'Architecture', 'Time, seconds', 'Inference Engine Processing Time', 'time' )\n",
    "summaryPlot(stats_list, 'Architecture', 'Frames per second', 'Inference Engine FPS', 'fps' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Ubuntu)",
   "language": "python",
   "name": "c003-python_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
