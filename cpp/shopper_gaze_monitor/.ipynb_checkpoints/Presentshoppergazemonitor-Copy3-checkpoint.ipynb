{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shopper Gaze Monitor\n",
    "\n",
    "This shopper gaze monitor application is one of a series of reference implementations for Computer Vision (CV) using the Intel® Distribution of OpenVINO™ toolkit. It is designed for a retail shelf mounted camera system that counts the number of passers-by that look towards the display vs. the number of people that pass by the display without looking. It is intended to provide real-world marketing statistics for in-store shelf-space advertising.\n",
    "\n",
    "# How it works\n",
    "\n",
    "The application uses a video source, such as a camera, to grab frames, and then uses 2 different Deep Neural Networks (DNNs) to process the data. The first neural network detect faces. If the person's face is detected, it is counted as a \"shopper\".\n",
    "\n",
    "A second neural network is then used to determine the head pose detection for each detected face. If the person's head is facing towards the camera, it is counted as a \"looker\".\n",
    "\n",
    "The data can then optionally be sent to a MQTT machine to machine messaging server, as part of a retail data analytics system.\n",
    "\n",
    "The DNN models can be downloaded using ./downloader.py present in model downloader folder that is part of the Intel® Distribution of OpenVINO™ toolkit.\n",
    "\n",
    "\n",
    "The program creates three threads for concurrency:\n",
    "\n",
    " ->main thread that performs the video i/o\n",
    " ->worker thread that processes video frames using the deep neural networks\n",
    " ->worker thread that publishes any MQTT messages\n",
    " \n",
    " \n",
    " # Set Up\n",
    "    \n",
    "Run the below cell to import Python dependencies needed for displaying the results in this notebook (tip: select the cell and use Ctrl+enter to run the cell)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path().resolve().parent.parent))\n",
    "from demoTools.demoutils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the code\n",
    "\n",
    "Start by changing the current directory to wherever you have the application code and build it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor\n"
     ]
    }
   ],
   "source": [
    "cd /home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mkdir build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor/build\n"
     ]
    }
   ],
   "source": [
    "cd build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- The C compiler identification is GNU 5.4.0\n",
      "-- The CXX compiler identification is GNU 5.4.0\n",
      "-- Check for working C compiler: /usr/bin/cc\n",
      "-- Check for working C compiler: /usr/bin/cc -- works\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- Check for working CXX compiler: /usr/bin/c++\n",
      "-- Check for working CXX compiler: /usr/bin/c++ -- works\n",
      "-- Detecting CXX compiler ABI info\n",
      "-- Detecting CXX compiler ABI info - done\n",
      "-- Detecting CXX compile features\n",
      "-- Detecting CXX compile features - done\n",
      "-- \u001b[1;34mIntel Shopper Gaze Monitor\u001b[m\n",
      "-- \u001b[1;34mChecking OS version...\u001b[m\n",
      "-- \u001b[1;34mChecking prerequisites...\u001b[m\n",
      "-- Intel OpenVINO was found\n",
      "-- OpenCV_INCLUDE_DIRS=/opt/intel/openvino_2019.1.094/opencv/include\n",
      "-- OpenCV_LIBS=opencv_imgproc;opencv_video;opencv_core;opencv_videoio;opencv_ml;opencv_stitching;opencv_features2d;opencv_flann;opencv_photo;opencv_imgcodecs;opencv_gapi;opencv_objdetect;opencv_dnn;opencv_calib3d;opencv_highgui;opencv_pvl\n",
      "-- Found Git: /usr/bin/git (found version \"2.7.4\") \n",
      "-- Found PkgConfig: /usr/bin/pkg-config (found version \"0.29.1\") \n",
      "-- Checking for one of the modules 'openssl'\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor/build\n"
     ]
    }
   ],
   "source": [
    "!cmake .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mScanning dependencies of target pahomqtt\u001b[0m\n",
      "[  9%] \u001b[34m\u001b[1mCreating directories for 'pahomqtt'\u001b[0m\n",
      "[ 18%] \u001b[34m\u001b[1mPerforming download step (git clone) for 'pahomqtt'\u001b[0m\n",
      "Cloning into 'paho-src'...\n",
      "Already on 'master'\n",
      "Your branch is up-to-date with 'origin/master'.\n",
      "[ 27%] \u001b[34m\u001b[1mNo patch step for 'pahomqtt'\u001b[0m\n",
      "[ 36%] \u001b[34m\u001b[1mNo update step for 'pahomqtt'\u001b[0m\n",
      "[ 45%] \u001b[34m\u001b[1mPerforming configure step for 'pahomqtt'\u001b[0m\n",
      "-- The C compiler identification is GNU 5.4.0\n",
      "-- Check for working C compiler: /usr/bin/cc\n",
      "-- Check for working C compiler: /usr/bin/cc -- works\n",
      "-- Detecting C compiler ABI info\n",
      "-- Detecting C compiler ABI info - done\n",
      "-- Detecting C compile features\n",
      "-- Detecting C compile features - done\n",
      "-- CMake version: 3.5.1\n",
      "-- CMake system name: Linux\n",
      "-- Timestamp is 2019-08-20T06:28:11Z\n",
      "-- OpenSSL hints: \n",
      "-- OpenSSL headers found at /usr/include\n",
      "-- OpenSSL library found at /usr/lib/x86_64-linux-gnu/libssl.so\n",
      "-- OpenSSL Crypto library found at /usr/lib/x86_64-linux-gnu/libcrypto.so\n",
      "-- OpenSSL hints: \n",
      "-- OpenSSL headers found at /usr/include\n",
      "-- Configuring done\n",
      "-- Generating done\n",
      "-- Build files have been written to: /home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor/build/pahomqtt-prefix/src/pahomqtt-build\n",
      "[ 54%] \u001b[34m\u001b[1mPerforming build step for 'pahomqtt'\u001b[0m\n",
      "\u001b[35m\u001b[1mScanning dependencies of target common_ssl_obj\u001b[0m\n",
      "[  1%] \u001b[32mBuilding C object src/CMakeFiles/common_ssl_obj.dir/MQTTProtocolClient.c.o\u001b[0m\n",
      "[  2%] \u001b[32mBuilding C object src/CMakeFiles/common_ssl_obj.dir/Clients.c.o\u001b[0m\n",
      "[  3%] \u001b[32mBuilding C object src/CMakeFiles/common_ssl_obj.dir/utf-8.c.o\u001b[0m\n",
      "[  4%] \u001b[32mBuilding C object src/CMakeFiles/common_ssl_obj.dir/StackTrace.c.o\u001b[0m\n",
      "[  5%] \u001b[32mBuilding C object src/CMakeFiles/common_ssl_obj.dir/MQTTPacket.c.o\u001b[0m\n",
      "[  6%] \u001b[32mBuilding C object src/CMakeFiles/common_ssl_obj.dir/MQTTPacketOut.c.o\u001b[0m\n",
      "[  7%] \u001b[32mBuilding C object src/CMakeFiles/common_ssl_obj.dir/Messages.c.o\u001b[0m\n",
      "[  8%] \u001b[32mBuilding C object src/CMakeFiles/common_ssl_obj.dir/Tree.c.o\u001b[0m\n",
      "[ 10%] \u001b[32mBuilding C object src/CMakeFiles/common_ssl_obj.dir/Socket.c.o\u001b[0m\n",
      "[ 11%] \u001b[32mBuilding C object src/CMakeFiles/common_ssl_obj.dir/Log.c.o\u001b[0m\n",
      "[ 12%] \u001b[32mBuilding C object src/CMakeFiles/common_ssl_obj.dir/MQTTPersistence.c.o\u001b[0m\n",
      "[ 13%] \u001b[32mBuilding C object src/CMakeFiles/common_ssl_obj.dir/Thread.c.o\u001b[0m\n",
      "[ 14%] \u001b[32mBuilding C object src/CMakeFiles/common_ssl_obj.dir/MQTTProtocolOut.c.o\u001b[0m\n",
      "[ 15%] \u001b[32mBuilding C object src/CMakeFiles/common_ssl_obj.dir/MQTTPersistenceDefault.c.o\u001b[0m\n",
      "[ 16%] \u001b[32mBuilding C object src/CMakeFiles/common_ssl_obj.dir/SocketBuffer.c.o\u001b[0m\n",
      "[ 17%] \u001b[32mBuilding C object src/CMakeFiles/common_ssl_obj.dir/Heap.c.o\u001b[0m\n",
      "[ 19%] \u001b[32mBuilding C object src/CMakeFiles/common_ssl_obj.dir/LinkedList.c.o\u001b[0m\n",
      "[ 20%] \u001b[32mBuilding C object src/CMakeFiles/common_ssl_obj.dir/MQTTProperties.c.o\u001b[0m\n",
      "[ 21%] \u001b[32mBuilding C object src/CMakeFiles/common_ssl_obj.dir/MQTTReasonCodes.c.o\u001b[0m\n",
      "[ 22%] \u001b[32mBuilding C object src/CMakeFiles/common_ssl_obj.dir/Base64.c.o\u001b[0m\n",
      "[ 23%] \u001b[32mBuilding C object src/CMakeFiles/common_ssl_obj.dir/SHA1.c.o\u001b[0m\n",
      "[ 24%] \u001b[32mBuilding C object src/CMakeFiles/common_ssl_obj.dir/WebSocket.c.o\u001b[0m\n",
      "[ 24%] Built target common_ssl_obj\n",
      "\u001b[35m\u001b[1mScanning dependencies of target common_obj\u001b[0m\n",
      "[ 25%] \u001b[32mBuilding C object src/CMakeFiles/common_obj.dir/MQTTProtocolClient.c.o\u001b[0m\n",
      "[ 26%] \u001b[32mBuilding C object src/CMakeFiles/common_obj.dir/Clients.c.o\u001b[0m\n",
      "[ 28%] \u001b[32mBuilding C object src/CMakeFiles/common_obj.dir/utf-8.c.o\u001b[0m\n",
      "[ 29%] \u001b[32mBuilding C object src/CMakeFiles/common_obj.dir/StackTrace.c.o\u001b[0m\n",
      "[ 30%] \u001b[32mBuilding C object src/CMakeFiles/common_obj.dir/MQTTPacket.c.o\u001b[0m\n",
      "[ 31%] \u001b[32mBuilding C object src/CMakeFiles/common_obj.dir/MQTTPacketOut.c.o\u001b[0m\n",
      "[ 32%] \u001b[32mBuilding C object src/CMakeFiles/common_obj.dir/Messages.c.o\u001b[0m\n",
      "[ 33%] \u001b[32mBuilding C object src/CMakeFiles/common_obj.dir/Tree.c.o\u001b[0m\n",
      "[ 34%] \u001b[32mBuilding C object src/CMakeFiles/common_obj.dir/Socket.c.o\u001b[0m\n",
      "[ 35%] \u001b[32mBuilding C object src/CMakeFiles/common_obj.dir/Log.c.o\u001b[0m\n",
      "[ 37%] \u001b[32mBuilding C object src/CMakeFiles/common_obj.dir/MQTTPersistence.c.o\u001b[0m\n",
      "[ 38%] \u001b[32mBuilding C object src/CMakeFiles/common_obj.dir/Thread.c.o\u001b[0m\n",
      "[ 39%] \u001b[32mBuilding C object src/CMakeFiles/common_obj.dir/MQTTProtocolOut.c.o\u001b[0m\n",
      "[ 40%] \u001b[32mBuilding C object src/CMakeFiles/common_obj.dir/MQTTPersistenceDefault.c.o\u001b[0m\n",
      "[ 41%] \u001b[32mBuilding C object src/CMakeFiles/common_obj.dir/SocketBuffer.c.o\u001b[0m\n",
      "[ 42%] \u001b[32mBuilding C object src/CMakeFiles/common_obj.dir/Heap.c.o\u001b[0m\n",
      "[ 43%] \u001b[32mBuilding C object src/CMakeFiles/common_obj.dir/LinkedList.c.o\u001b[0m\n",
      "[ 44%] \u001b[32mBuilding C object src/CMakeFiles/common_obj.dir/MQTTProperties.c.o\u001b[0m\n",
      "[ 46%] \u001b[32mBuilding C object src/CMakeFiles/common_obj.dir/MQTTReasonCodes.c.o\u001b[0m\n",
      "[ 47%] \u001b[32mBuilding C object src/CMakeFiles/common_obj.dir/Base64.c.o\u001b[0m\n",
      "[ 48%] \u001b[32mBuilding C object src/CMakeFiles/common_obj.dir/SHA1.c.o\u001b[0m\n",
      "[ 49%] \u001b[32mBuilding C object src/CMakeFiles/common_obj.dir/WebSocket.c.o\u001b[0m\n",
      "[ 49%] Built target common_obj\n",
      "\u001b[35m\u001b[1mScanning dependencies of target paho-mqtt3c\u001b[0m\n",
      "[ 50%] \u001b[32mBuilding C object src/CMakeFiles/paho-mqtt3c.dir/MQTTClient.c.o\u001b[0m\n",
      "[ 51%] \u001b[32m\u001b[1mLinking C shared library libpaho-mqtt3c.so\u001b[0m\n",
      "[ 51%] Built target paho-mqtt3c\n",
      "\u001b[35m\u001b[1mScanning dependencies of target paho-mqtt3cs\u001b[0m\n",
      "[ 52%] \u001b[32mBuilding C object src/CMakeFiles/paho-mqtt3cs.dir/MQTTClient.c.o\u001b[0m\n",
      "[ 53%] \u001b[32mBuilding C object src/CMakeFiles/paho-mqtt3cs.dir/SSLSocket.c.o\u001b[0m\n",
      "[ 55%] \u001b[32m\u001b[1mLinking C shared library libpaho-mqtt3cs.so\u001b[0m\n",
      "[ 55%] Built target paho-mqtt3cs\n",
      "\u001b[35m\u001b[1mScanning dependencies of target paho-mqtt3a\u001b[0m\n",
      "[ 56%] \u001b[32mBuilding C object src/CMakeFiles/paho-mqtt3a.dir/MQTTAsync.c.o\u001b[0m\n",
      "[ 57%] \u001b[32m\u001b[1mLinking C shared library libpaho-mqtt3a.so\u001b[0m\n",
      "[ 57%] Built target paho-mqtt3a\n",
      "\u001b[35m\u001b[1mScanning dependencies of target paho-mqtt3as\u001b[0m\n",
      "[ 58%] \u001b[32mBuilding C object src/CMakeFiles/paho-mqtt3as.dir/MQTTAsync.c.o\u001b[0m\n",
      "[ 59%] \u001b[32mBuilding C object src/CMakeFiles/paho-mqtt3as.dir/SSLSocket.c.o\u001b[0m\n",
      "[ 60%] \u001b[32m\u001b[1mLinking C shared library libpaho-mqtt3as.so\u001b[0m\n",
      "[ 60%] Built target paho-mqtt3as\n",
      "\u001b[35m\u001b[1mScanning dependencies of target MQTTVersion\u001b[0m\n",
      "[ 61%] \u001b[32mBuilding C object src/CMakeFiles/MQTTVersion.dir/MQTTVersion.c.o\u001b[0m\n",
      "[ 62%] \u001b[32m\u001b[1mLinking C executable MQTTVersion\u001b[0m\n",
      "[ 62%] Built target MQTTVersion\n",
      "\u001b[35m\u001b[1mScanning dependencies of target test45\u001b[0m\n",
      "[ 64%] \u001b[32mBuilding C object test/CMakeFiles/test45.dir/test45.c.o\u001b[0m\n",
      "[ 65%] \u001b[32m\u001b[1mLinking C executable test45\u001b[0m\n",
      "[ 65%] Built target test45\n",
      "\u001b[35m\u001b[1mScanning dependencies of target test8\u001b[0m\n",
      "[ 66%] \u001b[32mBuilding C object test/CMakeFiles/test8.dir/test8.c.o\u001b[0m\n",
      "[ 67%] \u001b[32m\u001b[1mLinking C executable test8\u001b[0m\n",
      "[ 67%] Built target test8\n",
      "\u001b[35m\u001b[1mScanning dependencies of target test4\u001b[0m\n",
      "[ 68%] \u001b[32mBuilding C object test/CMakeFiles/test4.dir/test4.c.o\u001b[0m\n",
      "[ 69%] \u001b[32m\u001b[1mLinking C executable test4\u001b[0m\n",
      "[ 69%] Built target test4\n",
      "\u001b[35m\u001b[1mScanning dependencies of target test3\u001b[0m\n",
      "[ 70%] \u001b[32mBuilding C object test/CMakeFiles/test3.dir/test3.c.o\u001b[0m\n",
      "[ 71%] \u001b[32m\u001b[1mLinking C executable test3\u001b[0m\n",
      "[ 71%] Built target test3\n",
      "\u001b[35m\u001b[1mScanning dependencies of target test5\u001b[0m\n",
      "[ 73%] \u001b[32mBuilding C object test/CMakeFiles/test5.dir/test5.c.o\u001b[0m\n",
      "[ 74%] \u001b[32m\u001b[1mLinking C executable test5\u001b[0m\n",
      "[ 74%] Built target test5\n",
      "\u001b[35m\u001b[1mScanning dependencies of target test10\u001b[0m\n",
      "[ 75%] \u001b[32mBuilding C object test/CMakeFiles/test10.dir/test10.c.o\u001b[0m\n",
      "[ 76%] \u001b[32m\u001b[1mLinking C executable test10\u001b[0m\n",
      "[ 76%] Built target test10\n",
      "\u001b[35m\u001b[1mScanning dependencies of target thread\u001b[0m\n",
      "[ 77%] \u001b[32mBuilding C object test/CMakeFiles/thread.dir/thread.c.o\u001b[0m\n",
      "[ 78%] \u001b[32mBuilding C object test/CMakeFiles/thread.dir/__/src/Thread.c.o\u001b[0m\n",
      "[ 79%] \u001b[32m\u001b[1mLinking C executable thread\u001b[0m\n",
      "[ 79%] Built target thread\n",
      "\u001b[35m\u001b[1mScanning dependencies of target test15\u001b[0m\n",
      "[ 80%] \u001b[32mBuilding C object test/CMakeFiles/test15.dir/test15.c.o\u001b[0m\n",
      "[ 82%] \u001b[32m\u001b[1mLinking C executable test15\u001b[0m\n",
      "[ 82%] Built target test15\n",
      "\u001b[35m\u001b[1mScanning dependencies of target test1\u001b[0m\n",
      "[ 83%] \u001b[32mBuilding C object test/CMakeFiles/test1.dir/test1.c.o\u001b[0m\n",
      "[ 84%] \u001b[32m\u001b[1mLinking C executable test1\u001b[0m\n",
      "[ 84%] Built target test1\n",
      "\u001b[35m\u001b[1mScanning dependencies of target test6\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 85%] \u001b[32mBuilding C object test/CMakeFiles/test6.dir/test6.c.o\u001b[0m\n",
      "[ 86%] \u001b[32m\u001b[1mLinking C executable test6\u001b[0m\n",
      "[ 86%] Built target test6\n",
      "\u001b[35m\u001b[1mScanning dependencies of target test_issue373\u001b[0m\n",
      "[ 87%] \u001b[32mBuilding C object test/CMakeFiles/test_issue373.dir/test_issue373.c.o\u001b[0m\n",
      "[ 88%] \u001b[32m\u001b[1mLinking C executable test_issue373\u001b[0m\n",
      "[ 88%] Built target test_issue373\n",
      "\u001b[35m\u001b[1mScanning dependencies of target test9\u001b[0m\n",
      "[ 89%] \u001b[32mBuilding C object test/CMakeFiles/test9.dir/test9.c.o\u001b[0m\n",
      "[ 91%] \u001b[32m\u001b[1mLinking C executable test9\u001b[0m\n",
      "[ 91%] Built target test9\n",
      "\u001b[35m\u001b[1mScanning dependencies of target test2\u001b[0m\n",
      "[ 92%] \u001b[32mBuilding C object test/CMakeFiles/test2.dir/test2.c.o\u001b[0m\n",
      "[ 93%] \u001b[32m\u001b[1mLinking C executable test2\u001b[0m\n",
      "[ 93%] Built target test2\n",
      "\u001b[35m\u001b[1mScanning dependencies of target test95\u001b[0m\n",
      "[ 94%] \u001b[32mBuilding C object test/CMakeFiles/test95.dir/test95.c.o\u001b[0m\n",
      "[ 95%] \u001b[32m\u001b[1mLinking C executable test95\u001b[0m\n",
      "[ 95%] Built target test95\n",
      "\u001b[35m\u001b[1mScanning dependencies of target test11\u001b[0m\n",
      "[ 96%] \u001b[32mBuilding C object test/CMakeFiles/test11.dir/test11.c.o\u001b[0m\n",
      "[ 97%] \u001b[32m\u001b[1mLinking C executable test11\u001b[0m\n",
      "[ 97%] Built target test11\n",
      "\u001b[35m\u001b[1mScanning dependencies of target test_sync_session_present\u001b[0m\n",
      "[ 98%] \u001b[32mBuilding C object test/CMakeFiles/test_sync_session_present.dir/test_sync_session_present.c.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking C executable test_sync_session_present\u001b[0m\n",
      "[100%] Built target test_sync_session_present\n",
      "[ 63%] \u001b[34m\u001b[1mPerforming install step for 'pahomqtt'\u001b[0m\n",
      "[ 24%] Built target common_ssl_obj\n",
      "[ 49%] Built target common_obj\n",
      "[ 51%] Built target paho-mqtt3c\n",
      "[ 55%] Built target paho-mqtt3cs\n",
      "[ 57%] Built target paho-mqtt3a\n",
      "[ 60%] Built target paho-mqtt3as\n",
      "[ 62%] Built target MQTTVersion\n",
      "[ 65%] Built target test45\n",
      "[ 67%] Built target test8\n",
      "[ 69%] Built target test4\n",
      "[ 71%] Built target test3\n",
      "[ 74%] Built target test5\n",
      "[ 76%] Built target test10\n",
      "[ 79%] Built target thread\n",
      "[ 82%] Built target test15\n",
      "[ 84%] Built target test1\n",
      "[ 86%] Built target test6\n",
      "[ 88%] Built target test_issue373\n",
      "[ 91%] Built target test9\n",
      "[ 93%] Built target test2\n",
      "[ 95%] Built target test95\n",
      "[ 97%] Built target test11\n",
      "[100%] Built target test_sync_session_present\n",
      "\u001b[36mInstall the project...\u001b[0m\n",
      "-- Install configuration: \"\"\n",
      "-- Installing: /home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor/build/paho-build/samples/MQTTClient_subscribe.c\n",
      "-- Installing: /home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor/build/paho-build/samples/MQTTAsync_subscribe.c\n",
      "-- Installing: /home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor/build/paho-build/samples/paho_c_sub.c\n",
      "-- Installing: /home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor/build/paho-build/samples/MQTTClient_publish_async.c\n",
      "-- Installing: /home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor/build/paho-build/samples/paho_cs_pub.c\n",
      "-- Installing: /home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor/build/paho-build/samples/paho_c_pub.c\n",
      "-- Installing: /home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor/build/paho-build/samples/pubsub_opts.c\n",
      "-- Installing: /home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor/build/paho-build/samples/MQTTAsync_publish.c\n",
      "-- Installing: /home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor/build/paho-build/samples/paho_cs_sub.c\n",
      "-- Installing: /home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor/build/paho-build/samples/MQTTClient_publish.c\n",
      "-- Installing: /home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor/build/paho-build/./CONTRIBUTING.md\n",
      "-- Installing: /home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor/build/paho-build/./epl-v10\n",
      "-- Installing: /home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor/build/paho-build/./edl-v10\n",
      "-- Installing: /home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor/build/paho-build/./README.md\n",
      "-- Installing: /home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor/build/paho-build/./notice.html\n",
      "-- Installing: /home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor/build/paho-build/lib/libpaho-mqtt3c.so.1.3.1\n",
      "-- Installing: /home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor/build/paho-build/lib/libpaho-mqtt3c.so.1\n",
      "-- Installing: /home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor/build/paho-build/lib/libpaho-mqtt3c.so\n",
      "-- Installing: /home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor/build/paho-build/lib/libpaho-mqtt3a.so.1.3.1\n",
      "-- Installing: /home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor/build/paho-build/lib/libpaho-mqtt3a.so.1\n",
      "-- Installing: /home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor/build/paho-build/lib/libpaho-mqtt3a.so\n",
      "-- Installing: /home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor/build/paho-build/bin/MQTTVersion\n",
      "-- Set runtime path of \"/home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor/build/paho-build/bin/MQTTVersion\" to \"\"\n",
      "-- Installing: /home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor/build/paho-build/include/MQTTAsync.h\n",
      "-- Installing: /home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor/build/paho-build/include/MQTTClient.h\n",
      "-- Installing: /home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor/build/paho-build/include/MQTTClientPersistence.h\n",
      "-- Installing: /home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor/build/paho-build/include/MQTTProperties.h\n",
      "-- Installing: /home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor/build/paho-build/include/MQTTReasonCodes.h\n",
      "-- Installing: /home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor/build/paho-build/include/MQTTSubscribeOpts.h\n",
      "-- Installing: /home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor/build/paho-build/lib/libpaho-mqtt3cs.so.1.3.1\n",
      "-- Installing: /home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor/build/paho-build/lib/libpaho-mqtt3cs.so.1\n",
      "-- Installing: /home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor/build/paho-build/lib/libpaho-mqtt3cs.so\n",
      "-- Installing: /home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor/build/paho-build/lib/libpaho-mqtt3as.so.1.3.1\n",
      "-- Installing: /home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor/build/paho-build/lib/libpaho-mqtt3as.so.1\n",
      "-- Installing: /home/u26213/Reference-samples/iot-devcloud/cpp/shopper_gaze_monitor/build/paho-build/lib/libpaho-mqtt3as.so\n",
      "[ 72%] \u001b[34m\u001b[1mCompleted 'pahomqtt'\u001b[0m\n",
      "[ 72%] Built target pahomqtt\n",
      "\u001b[35m\u001b[1mScanning dependencies of target monitor\u001b[0m\n",
      "[ 81%] \u001b[32mBuilding CXX object CMakeFiles/monitor.dir/src/main.cpp.o\u001b[0m\n",
      "[ 90%] \u001b[32mBuilding CXX object CMakeFiles/monitor.dir/src/mqtt.cpp.o\u001b[0m\n",
      "[100%] \u001b[32m\u001b[1mLinking CXX executable monitor\u001b[0m\n",
      "[100%] Built target monitor\n"
     ]
    }
   ],
   "source": [
    "!make"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above produces an executable monitor. This executable takes in a number of different command line arguments.\n",
    "\n",
    "Run the following cell to see the list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use this script to using OpenVINO.\n",
      "Usage: monitor [params] \n",
      "\n",
      "\t-b, --backend (value:0)\n",
      "\t\tChoose one of computation backends: 0: automatically (by default), 1: Halide language (http://halide-lang.org/), 2: Intel's Deep Learning Inference Engine (https://software.intel.com/openvino-toolkit), 3: OpenCV implementation\n",
      "\t-c, --config\n",
      "\t\tPath to .xml file of model containing network configuration.\n",
      "\t-d, --device (value:0)\n",
      "\t\tcamera device number.\n",
      "\t-h, --help (value:true)\n",
      "\t\tPrint help message.\n",
      "\t-i, --input\n",
      "\t\tPath to input image or video file. Skip this argument to capture frames from a camera.\n",
      "\t-m, --model\n",
      "\t\tPath to .bin file of model containing face recognizer.\n",
      "\t-o, --output\n",
      "\t\tPath to output image or video file.\n",
      "\t--pc, --poseconfig\n",
      "\t\tPath to a .xml file of face pose model containing network configuration.\n",
      "\t--pm, --posemodel\n",
      "\t\tPath to .bin file of face pose model.\n",
      "\t-r, --rate (value:1)\n",
      "\t\tnumber of seconds between data updates to MQTT server.\n",
      "\t-t, --target (value:0)\n",
      "\t\tChoose one of target computation devices: 0: CPU target (by default), 1: OpenCL, 2: OpenCL fp16 (half-float precision), 3: VPU,5: HETERO:FPGA,CPU\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "./monitor -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The version of the cpp file here is a slightly modified version of the shopper gaze monitor code built-in to the the Intel® Distribution of OpenVINO™ toolkit. In this version, the result is written into a output mp4 file specified by the -o flag."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading IR Model\n",
    "\n",
    "The Intel® Distribution of OpenVINO™ toolkit comes with model downloader that can download pre-compiled Intermediate Representation (IR) models that are optimized for different end-point target devices. These models can be created from existing DNN models from popular frameworks (e.g. Caffe*, TF) using the Model Optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "densenet-121\r\n",
      "densenet-161\r\n",
      "densenet-169\r\n",
      "densenet-201\r\n",
      "squeezenet1.0\r\n",
      "squeezenet1.1\r\n",
      "mtcnn-p\r\n",
      "mtcnn-r\r\n",
      "mtcnn-o\r\n",
      "mobilenet-ssd\r\n",
      "vgg19\r\n",
      "vgg16\r\n",
      "ssd512\r\n",
      "ssd300\r\n",
      "inception-resnet-v2\r\n",
      "dilation\r\n",
      "googlenet-v1\r\n",
      "googlenet-v2\r\n",
      "googlenet-v4\r\n",
      "alexnet\r\n",
      "ssd_mobilenet_v2_coco\r\n",
      "resnet-50\r\n",
      "resnet-101\r\n",
      "resnet-152\r\n",
      "googlenet-v3\r\n",
      "se-inception\r\n",
      "se-resnet-101\r\n",
      "se-resnet-152\r\n",
      "se-resnet-50\r\n",
      "se-resnext-50\r\n",
      "se-resnext-101\r\n",
      "Sphereface\r\n",
      "license-plate-recognition-barrier-0007\r\n",
      "mobilenet-v1-1.0-224\r\n",
      "mobilenet-v2\r\n",
      "faster_rcnn_inception_v2_coco\r\n",
      "deeplabv3\r\n",
      "ctpn\r\n",
      "ssd_mobilenet_v1_coco\r\n",
      "faster_rcnn_resnet101_coco\r\n",
      "mobilenet-v2-1.4-224\r\n",
      "age-gender-recognition-retail-0013\r\n",
      "age-gender-recognition-retail-0013-fp16\r\n",
      "emotions-recognition-retail-0003\r\n",
      "emotions-recognition-retail-0003-fp16\r\n",
      "face-detection-adas-0001\r\n",
      "face-detection-adas-0001-fp16\r\n",
      "face-detection-retail-0004\r\n",
      "face-detection-retail-0004-fp16\r\n",
      "face-person-detection-retail-0002\r\n",
      "face-person-detection-retail-0002-fp16\r\n",
      "face-reidentification-retail-0095\r\n",
      "face-reidentification-retail-0095-fp16\r\n",
      "facial-landmarks-35-adas-0002\r\n",
      "facial-landmarks-35-adas-0002-fp16\r\n",
      "head-pose-estimation-adas-0001\r\n",
      "head-pose-estimation-adas-0001-fp16\r\n",
      "human-pose-estimation-0001\r\n",
      "human-pose-estimation-0001-fp16\r\n",
      "landmarks-regression-retail-0009\r\n",
      "landmarks-regression-retail-0009-fp16\r\n",
      "license-plate-recognition-barrier-0001\r\n",
      "license-plate-recognition-barrier-0001-fp16\r\n",
      "pedestrian-and-vehicle-detector-adas-0001\r\n",
      "pedestrian-and-vehicle-detector-adas-0001-fp16\r\n",
      "pedestrian-detection-adas-0002\r\n",
      "pedestrian-detection-adas-0002-fp16\r\n",
      "person-attributes-recognition-crossroad-0230\r\n",
      "person-attributes-recognition-crossroad-0230-fp16\r\n",
      "person-detection-action-recognition-0005\r\n",
      "person-detection-action-recognition-0005-fp16\r\n",
      "person-detection-retail-0002\r\n",
      "person-detection-retail-0002-fp16\r\n",
      "person-detection-retail-0013\r\n",
      "person-detection-retail-0013-fp16\r\n",
      "person-reidentification-retail-0031\r\n",
      "person-reidentification-retail-0031-fp16\r\n",
      "person-reidentification-retail-0076\r\n",
      "person-reidentification-retail-0076-fp16\r\n",
      "person-reidentification-retail-0079\r\n",
      "person-reidentification-retail-0079-fp16\r\n",
      "person-vehicle-bike-detection-crossroad-0078\r\n",
      "person-vehicle-bike-detection-crossroad-0078-fp16\r\n",
      "road-segmentation-adas-0001\r\n",
      "road-segmentation-adas-0001-fp16\r\n",
      "semantic-segmentation-adas-0001\r\n",
      "semantic-segmentation-adas-0001-fp16\r\n",
      "single-image-super-resolution-1033\r\n",
      "single-image-super-resolution-1033-fp16\r\n",
      "text-detection-0002\r\n",
      "text-detection-0002-fp16\r\n",
      "vehicle-attributes-recognition-barrier-0039\r\n",
      "vehicle-attributes-recognition-barrier-0039-fp16\r\n",
      "vehicle-detection-adas-0002\r\n",
      "vehicle-detection-adas-0002-fp16\r\n",
      "vehicle-license-plate-detection-barrier-0106\r\n",
      "vehicle-license-plate-detection-barrier-0106-fp16\r\n",
      "face-detection-adas-binary-0001\r\n",
      "single-image-super-resolution-1032\r\n",
      "single-image-super-resolution-1032-fp16\r\n",
      "action-recognition-0001-encoder\r\n",
      "action-recognition-0001-encoder-fp16\r\n",
      "instance-segmentation-security-0049\r\n",
      "instance-segmentation-security-0049-fp16\r\n",
      "vehicle-detection-adas-binary-0001\r\n",
      "driver-action-recognition-adas-0002-decoder\r\n",
      "driver-action-recognition-adas-0002-decoder-fp16\r\n",
      "pedestrian-detection-adas-binary-0001\r\n",
      "person-detection-action-recognition-teacher-0002\r\n",
      "person-detection-action-recognition-teacher-0002-fp16\r\n",
      "instance-segmentation-security-0033\r\n",
      "instance-segmentation-security-0033-fp16\r\n",
      "action-recognition-0001-decoder\r\n",
      "action-recognition-0001-decoder-fp16\r\n",
      "text-recognition-0012\r\n",
      "text-recognition-0012-fp16\r\n",
      "driver-action-recognition-adas-0002-encoder\r\n",
      "driver-action-recognition-adas-0002-encoder-fp16\r\n",
      "gaze-estimation-adas-0002\r\n",
      "gaze-estimation-adas-0002-fp16\r\n",
      "resnet50-binary-0001\r\n"
     ]
    }
   ],
   "source": [
    "!/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --print_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note the '!' is a special Jupyter Notebook command that allows you to run shell commands as if you are in a commannd line. So the above command will work straight out of the box on in a terminal (with '!' removed).\n",
    "\n",
    "In this demo we will be using the 4 different types of models, with two model files each for FP16 and FP32. These models can be downloaded with the following command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###############|| Downloading topologies ||###############\n",
      "\n",
      "========= Downloading models/Transportation/object_detection/face/pruned_mobilenet_reduced_ssd_shared_weights/dldt/face-detection-adas-0001.xml\n",
      "... 100%, 88 KB, 2233 KB/s, 0 seconds passed\n",
      "\n",
      "========= Downloading models/Transportation/object_detection/face/pruned_mobilenet_reduced_ssd_shared_weights/dldt/face-detection-adas-0001.bin\n",
      "... 100%, 4113 KB, 29214 KB/s, 0 seconds passed\n",
      "\n",
      "\n",
      "###############|| Post processing ||###############\n",
      "\n",
      "\n",
      "###############|| Downloading topologies ||###############\n",
      "\n",
      "========= Downloading models/Transportation/object_detection/face/pruned_mobilenet_reduced_ssd_shared_weights/dldt/face-detection-adas-0001-fp16.xml\n",
      "... 100%, 88 KB, 4130 KB/s, 0 seconds passed\n",
      "\n",
      "========= Downloading models/Transportation/object_detection/face/pruned_mobilenet_reduced_ssd_shared_weights/dldt/face-detection-adas-0001-fp16.bin\n",
      "... 100%, 2056 KB, 29600 KB/s, 0 seconds passed\n",
      "\n",
      "\n",
      "###############|| Post processing ||###############\n",
      "\n",
      "\n",
      "###############|| Downloading topologies ||###############\n",
      "\n",
      "========= Downloading models/Transportation/object_attributes/headpose/vanilla_cnn/dldt/head-pose-estimation-adas-0001.xml\n",
      "... 100%, 17 KB, 39146 KB/s, 0 seconds passed\n",
      "\n",
      "========= Downloading models/Transportation/object_attributes/headpose/vanilla_cnn/dldt/head-pose-estimation-adas-0001.bin\n",
      "... 100%, 7466 KB, 28776 KB/s, 0 seconds passed\n",
      "\n",
      "\n",
      "###############|| Post processing ||###############\n",
      "\n",
      "\n",
      "###############|| Downloading topologies ||###############\n",
      "\n",
      "========= Downloading models/Transportation/object_attributes/headpose/vanilla_cnn/dldt/head-pose-estimation-adas-0001-fp16.xml\n",
      "... 100%, 17 KB, 53805 KB/s, 0 seconds passed\n",
      "\n",
      "========= Downloading models/Transportation/object_attributes/headpose/vanilla_cnn/dldt/head-pose-estimation-adas-0001-fp16.bin\n",
      "... 100%, 3733 KB, 28619 KB/s, 0 seconds passed\n",
      "\n",
      "\n",
      "###############|| Post processing ||###############\n",
      "\n",
      "\n",
      "###############|| Downloading topologies ||###############\n",
      "\n",
      "========= Downloading models/Retail/object_attributes/age_gender/dldt/age-gender-recognition-retail-0013.xml\n",
      "... 100%, 14 KB, 46607 KB/s, 0 seconds passed\n",
      "\n",
      "========= Downloading models/Retail/object_attributes/age_gender/dldt/age-gender-recognition-retail-0013.bin\n",
      "... 100%, 8351 KB, 28701 KB/s, 0 seconds passed\n",
      "\n",
      "\n",
      "###############|| Post processing ||###############\n",
      "\n",
      "\n",
      "###############|| Downloading topologies ||###############\n",
      "\n",
      "========= Downloading models/Retail/object_attributes/age_gender/dldt/age-gender-recognition-retail-0013-fp16.xml\n",
      "... 100%, 14 KB, 37058 KB/s, 0 seconds passed\n",
      "\n",
      "========= Downloading models/Retail/object_attributes/age_gender/dldt/age-gender-recognition-retail-0013-fp16.bin\n",
      "... 100%, 4175 KB, 28738 KB/s, 0 seconds passed\n",
      "\n",
      "\n",
      "###############|| Post processing ||###############\n",
      "\n",
      "\n",
      "###############|| Downloading topologies ||###############\n",
      "\n",
      "========= Downloading models/Retail/object_attributes/emotions_recognition/0003/dldt/emotions-recognition-retail-0003.xml\n",
      "... 100%, 19 KB, 41069 KB/s, 0 seconds passed\n",
      "\n",
      "========= Downloading models/Retail/object_attributes/emotions_recognition/0003/dldt/emotions-recognition-retail-0003.bin\n",
      "... 100%, 9697 KB, 28744 KB/s, 0 seconds passed\n",
      "\n",
      "\n",
      "###############|| Post processing ||###############\n",
      "\n",
      "\n",
      "###############|| Downloading topologies ||###############\n",
      "\n",
      "========= Downloading models/Retail/object_attributes/emotions_recognition/0003/dldt/emotions-recognition-retail-0003-fp16.xml\n",
      "... 100%, 19 KB, 51278 KB/s, 0 seconds passed\n",
      "\n",
      "========= Downloading models/Retail/object_attributes/emotions_recognition/0003/dldt/emotions-recognition-retail-0003-fp16.bin\n",
      "... 100%, 4848 KB, 28213 KB/s, 0 seconds passed\n",
      "\n",
      "\n",
      "###############|| Post processing ||###############\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name face-detection-adas-0001 -o models\n",
    "!/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name face-detection-adas-0001-fp16 -o models\n",
    "!/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name head-pose-estimation-adas-0001 -o models\n",
    "!/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name head-pose-estimation-adas-0001-fp16 -o models\n",
    "!/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name age-gender-recognition-retail-0013 -o models\n",
    "!/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name age-gender-recognition-retail-0013-fp16 -o models\n",
    "!/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name emotions-recognition-retail-0003 -o models\n",
    "!/opt/intel/openvino/deployment_tools/tools/model_downloader/downloader.py --name emotions-recognition-retail-0003-fp16 -o models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input arguments are as follows:\n",
    "\n",
    "--name : name of the model you want to download. It should be one of the models listed in the previous cell.\n",
    "-o : output directory. If this directory does not exist, it will be created.\n",
    "There are more arguments to this script and you can get the full list using the -h option.\n",
    "\n",
    "Running the inference\n",
    "Now we are ready to run the inference workload. In this step, we will be submitting the workload as a job to the job queue.\n",
    "\n",
    "Currently, you are on what is called a \"devnode\". On this system, you are allocated just one core on a large Intel® Xeon® CPU. The purpose of this node is to develop code on the devnode and run minimal sections of Jupyter* Notebooks, but it is not meant to compute intensive jobs like deep learning inference. So we need to request additional resources from the cluster of Edge nodes to run the inference and this is done through the job queue.\n",
    "\n",
    "To put an item on the job queue, we must first create a bash script that run the workload we want. Run the following cell to create bash script shopper_gaze.sh which will be our job script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing shopper_gaze.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile shopper_gaze.sh\n",
    "#PBS\n",
    "INPUT_FILE=$1\n",
    "OUTPUT_FILE=$2\n",
    "FP_MODEL=$3\n",
    "BACKEND=$4\n",
    "#0: CPU target (by default), 1: OpenCL, 2: OpenCL fp16 (half-float precision), 3: VPU,5: HETERO:FPGA,CPU\n",
    "TARGET=$5\n",
    "\n",
    "\n",
    "if [ \"$TARGET\" == \"5\" ]; then\n",
    "    # Environment variables and compilation for edge compute nodes with FPGAs\n",
    "    source /opt/fpga_support_files/setup_env.sh\n",
    "    aocl program acl0 /opt/intel/openvino/bitstreams/a10_vision_design_bitstreams/2019R1_PL1_FP11_MobileNet_Clamp.aocx\n",
    "fi\n",
    "\n",
    "cd $PBS_O_WORKDIR\n",
    "export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/opt/intel/openvino/deployment_tools/inference_engine/lib/intel64/\n",
    "\n",
    " \n",
    "if [ \"$FP_MODEL\" == \"FP16\" ]; then\n",
    "  FPEXT='-fp16'\n",
    "fi\n",
    "\n",
    "    \n",
    "./monitor \\\n",
    "-m=models/Transportation/object_detection/face/pruned_mobilenet_reduced_ssd_shared_weights/dldt/face-detection-adas-0001${FPEXT}.bin \\\n",
    "-c=models/Transportation/object_detection/face/pruned_mobilenet_reduced_ssd_shared_weights/dldt/face-detection-adas-0001${FPEXT}.xml \\\n",
    "-pm=models/Transportation/object_attributes/headpose/vanilla_cnn/dldt/head-pose-estimation-adas-0001${FPEXT}.bin \\\n",
    "-pc=models/Transportation/object_attributes/headpose/vanilla_cnn/dldt/head-pose-estimation-adas-0001${FPEXT}.xml \\\n",
    "-i=$INPUT_FILE \\\n",
    "-o=$OUTPUT_FILE \\\n",
    "-b=$BACKENED \\\n",
    "-t=$TARGET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To put this script on the job queue, we use the command qsub. There are two important arguments we use with this command.\n",
    "\n",
    "First, the -l flag. This flag is used to specify what type of resources to request from the cluster. For example this can be used to request an Intel® Xeon® CPU based system, or it can be used to request a system with an FPGA accelerator card in it. The syntax is -l nodes=1:<tag> where <tag> is the descriptor tag for the resource you want. For example, -l nodes=1:tank-870:e3-1268l-v5 will request an Intel® Xeon® system. To see the list of available tags, and the number of avilable systems, run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     35      properties = idc001skl,compnode,iei,tank-870,intel-core,i5-6500te,skylake,intel-hd-530,ram8gb,1gbe\r\n",
      "     15      properties = idc002mx8,compnode,iei,tank-870,intel-core,i5-6500te,skylake,intel-hd-530,ram8gb,net1gbe,hddl-r,iei-mustang-v100-mx8\r\n",
      "     18      properties = idc003a10,compnode,iei,tank-870,intel-core,i5-6500te,skylake,intel-hd-530,ram8gb,net1gbe,hddl-f,iei-mustang-f100-a10\r\n",
      "     23      properties = idc004nc2,compnode,iei,tank-870,intel-core,i5-6500te,skylake,intel-hd-530,ram8gb,net1gbe,ncs,intel-ncs2\r\n",
      "      6      properties = idc006kbl,compnode,iei,tank-870,intel-core,i5-7500t,kaby-lake,intel-hd-630,ram8gb,net1gbe\r\n",
      "     16      properties = idc007xv5,compnode,iei,tank-870,intel-xeon,e3-1268l-v5,skylake,intel-hd-p530,ram32gb,net1gbe\r\n",
      "     15      properties = idc008u2g,compnode,up-squared,grove,intel-atom,e3950,apollo-lake,intel-hd-505,ram4gb,net1gbe,ncs,intel-ncs2\r\n",
      "      1      properties = idc009jkl,compnode,jwip,intel-core,i5-7500,kaby-lake,intel-hd-630,ram8gb,net1gbe\r\n",
      "      1      properties = idc010jal,compnode,jwip,intel-atom,e3950,apollo-lake,intel-hd-505,ram4gb,net1gbe\r\n",
      "      2      properties = idc012ros,compnode,iei,tank-870,intel-core,i5-7500t,kaby-lake,intel-hd-630,ram8gb,net1gbe\r\n",
      "      1      properties = idc013agg,compnode,iei,tank-870,intel-core,i5-7500t,kaby-lake,intel-hd-630,ram8gb,net1gbe\r\n",
      "      1      properties = idc014col,compnode,iei,tank-870,intel-core,i5-7500t,kaby-lake,intel-hd-630,ram8gb,net1gbe\r\n"
     ]
    }
   ],
   "source": [
    "!pbsnodes | grep compnode | sort | uniq -c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then there is the -F flag, which is used to pass in arguments to the job script. The face_detection_demo.sh takes in 2 arguments: 1) the path to the video to run inference on. 2) targeted device (CPU,GPU,MYRIAD). The job scheduler will use the contents of -F flag as the argument to the job script.\n",
    "\n",
    "The following line will request an Intel Xeon system, and passes in \"faces-recognition-walking.mp4 CPU\" to the job script. Run the cell to submit this job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"VIDEO\"] = \"../resources/face-demographics-walking-and-pause.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting to an edge compute node with an Intel® Core™ CPU\n",
    "\n",
    "In the cell below, we submit a job to an IEI Tank 870-Q170 edge node with an Intel Core i5-6500TE. The inference workload will run on the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting job to Intel Core CPU...\n",
      "43993.c003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35aa0738d2394d22811b6d8d924991d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Inference', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Submitting job to Intel Core CPU...\")\n",
    "#Submit job to the queue\n",
    "job_id_core = !qsub shopper_gaze.sh -l nodes=1:tank-870:i5-6500te -F \"$VIDEO ../results/ FP32 2 0\"\n",
    "print(job_id_core[0])\n",
    "\n",
    "#Progress indicators\n",
    "if job_id_core:\n",
    "    progressIndicator('../results/', 'i_progress_'+job_id_core[0]+'.txt', \"Inference\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting to an edge compute node with Intel® Xeon® CPU\n",
    "In the cell below, we submit a job to an <a \n",
    "    href=\"https://software.intel.com/en-us/iot/hardware/iei-tank-dev-kit-core\">IEI \n",
    "    Tank* 870-Q170</a> edge node with an <a \n",
    "    href=\"https://ark.intel.com/products/88178/Intel-Xeon-Processor-E3-1268L-v5-8M-Cache-2-40-GHz-\">Intel® \n",
    "    Xeon® Processor E3-1268L v5</a>. The inference workload will run on the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting job to Intel Xeon CPU...\n",
      "44045.c003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76a0d590e30c4eb7b3a5aa15d79dedfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Inference', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Submitting job to Intel Xeon CPU...\")\n",
    "#Submit job to the queue\n",
    "job_id_xeon = !qsub shopper_gaze.sh -l nodes=1:tank-870:e3-1268l-v5 -F \"$VIDEO ../results/ FP32 2 0\"\n",
    "print(job_id_xeon[0]) \n",
    "#Progress indicators\n",
    "if job_id_xeon:\n",
    "    progressIndicator('../results/', 'i_progress_'+job_id_xeon[0]+'.txt', \"Inference\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting to an edge compute node with Intel® Core™ CPU and using the onboard Intel GPU\n",
    "\n",
    "In the cell below, we submit a job to an IEI Tank 870-Q170 edge node with an Intel Core i5-6500TE. The inference workload will run on the Intel® HD Graphics 530 card integrated with the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting job to Intel Core CPU with Intel GPU... FP32\n",
      "44106.c003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6712f81047a140baa283e1846350c654",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Inference', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Submitting job to Intel Core CPU with Intel GPU... FP32\")\n",
    "#Submit job to the queue\n",
    "job_id_gpu = !qsub shopper_gaze.sh -l nodes=1:tank-870:i5-6500te -F \"$VIDEO ../results/ FP32 2 1\"\n",
    "print(job_id_gpu[0])\n",
    "\n",
    "#Progress indicators\n",
    "if job_id_gpu:\n",
    "    progressIndicator('../results/', 'i_progress_'+job_id_gpu[0]+'.txt', \"Inference\", 0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting job to Intel Core CPU with Intel GPU... FP16\n",
      "44108.c003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "925c395a7bdb41f3b3f6c9927a0c171e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Inference', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Submitting job to Intel Core CPU with Intel GPU... FP16\")\n",
    "#Submit job to the queue\n",
    "job_id_gpu_fp16 = !qsub shopper_gaze.sh -l nodes=1:tank-870:i5-6500te -F \"$VIDEO ../results/ FP16 2 2\"\n",
    "print(job_id_gpu_fp16[0])\n",
    "\n",
    "#Progress indicators\n",
    "if job_id_gpu_fp16:\n",
    "    progressIndicator('../results/', 'i_progress_'+job_id_gpu_fp16[0]+'.txt', \"Inference\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting to an edge compute node with Intel® VPU\n",
    "\n",
    "In the cell below, we submit a job to an IEI Tank 870-Q170 edge node with an Intel Core™ i5-6500te CPU . The inference workload will run on the IEI Mustang-V100-MX8 card installed in this node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting job to node with Intel VPU...\n",
      "44112.c003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0d584e399c142a0a69706f72a06d9f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Inference', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Submitting job to node with Intel VPU...\")\n",
    "#Submit job to the queue\n",
    "job_id_hddl_fp16 = !qsub shopper_gaze.sh -l nodes=1:tank-870:iei-mustang-v100-mx8 -F \"$VIDEO ../results/ FP16 2 3\"\n",
    "print(job_id_hddl_fp16[0]) \n",
    "#Progress indicators\n",
    "if job_id_hddl_fp16:\n",
    "    progressIndicator('../results/', 'i_progress_'+job_id_hddl_fp16[0]+'.txt', \"Inference\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting to an edge compute node with IEI Mustang-F100-A10 (Intel® Arria® 10 FPGA)¶\n",
    "\n",
    "In the cell below, we submit a job to an IEI Tank 870-Q170 edge node with an Intel Core i5-6500te CPU . The inference workload will run on the IEI Mustang-F100-A10 card installed in this node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting job to node with Intel FPGA HDDL-F...\n",
      "44113.c003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb5d3019f93c42b0a7d3994c479dc005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, bar_style='info', description='Inference', style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Submitting job to node with Intel FPGA HDDL-F...\")\n",
    "#Submit job to the queue\n",
    "job_id_fpga_16 = !qsub shopper_gaze.sh -l nodes=1:i5-6500te:iei-mustang-f100-a10 -F \"$VIDEO ../results/ FP16 2 5\"\n",
    "print(job_id_fpga_16[0])\n",
    "\n",
    "#Progress indicators\n",
    "if job_id_fpga_16:\n",
    "    progressIndicator('../results/', 'i_progress_'+job_id_fpga_16[0]+'.txt', \"Inference\", 0, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if the jobs are done\n",
    "\n",
    "To check on the jobs that were submitted, use the `qstat` command.\n",
    "\n",
    "We have created a custom Jupyter widget  to get live qstat update.\n",
    "Run the following cell to bring it up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b6dd2a60464856969d299fa976cab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(border='1px solid gray', width='100%'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7edea05a2334852b7f81d54d9564155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Stop', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "liveQstat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see the jobs that you have submitted (referenced by `Job ID` that gets displayed right after you submit the job in step 2.3).\n",
    "There should also be an extra job in the queue \"jupyterhub\": this job runs your current Jupyter Notebook session.\n",
    "\n",
    "The 'S' column shows the current status. \n",
    "- If it is in Q state, it is in the queue waiting for available resources. \n",
    "- If it is in R state, it is running. \n",
    "- If the job is no longer listed, it means it is completed.\n",
    "\n",
    "**Note**: Time spent in the queue depends on the number of users accessing the edge nodes. Once these jobs begin to run, they should take from 1 to 5 minutes to complete. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Wait!***\n",
    "\n",
    "Please wait for the inference jobs and video rendering complete before proceeding to the next step.\n",
    "\n",
    "## Step 3: View Results\n",
    "\n",
    "Once the jobs are completed, the queue system outputs the stdout and stderr streams of each job into files with names of the form\n",
    "\n",
    "`obj_det_{type}.o{JobID}`\n",
    "\n",
    "`obj_det_{type}.e{JobID}`\n",
    "\n",
    "(here, obj_det_{type} corresponds to the `-N` option of qsub).\n",
    "\n",
    "However, for this case, we may be more interested in the output video files. They are stored in mp4 format inside the `results/` directory.\n",
    "We wrote a short utility script that will display these videos with in the notebook.\n",
    "Run the cells below to display them.\n",
    "See `demoutils.py` if you are interested in understanding further how the results are displayed in notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>IEI Tank Core (Intel Core CPU)</h2>\n",
       "    <p>1091\n",
       " frames processed in 92.872747\n",
       " seconds</p>\n",
       "    <video alt=\"\" controls autoplay height=\"480\"><source src=\"results/output_43993.c003.mp4\" type=\"video/mp4\" /></video>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videoHTML('IEI Tank Core (Intel Core CPU)',\n",
    "          ['results/output_'+job_id_core[0]+'.mp4'],\n",
    "          '../results/stats_'+job_id_core[0]+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>IEI Tank Core (Intel Xeon CPU)</h2>\n",
       "    <p>1091\n",
       " frames processed in 93.176258\n",
       " seconds</p>\n",
       "    <video alt=\"\" controls autoplay height=\"480\"><source src=\"results/output_44045.c003.mp4\" type=\"video/mp4\" /></video>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videoHTML('IEI Tank Core (Intel Xeon CPU)',\n",
    "          ['results/output_'+job_id_xeon[0]+'.mp4'],\n",
    "          '../results/stats_'+job_id_xeon[0]+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>IEI Intel GPU (Intel Core + Onboard GPU)</h2>\n",
       "    <p>1091\n",
       " frames processed in 93.166156\n",
       " seconds</p>\n",
       "    <video alt=\"\" controls autoplay height=\"480\"><source src=\"results/output_44106.c003.mp4\" type=\"video/mp4\" /></video>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videoHTML('IEI Intel GPU (Intel Core + Onboard GPU)', \n",
    "          ['results/output_'+job_id_gpu[0]+'.mp4'],\n",
    "          '../results/stats_'+job_id_gpu[0]+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>IEI Intel GPU (Intel Core + Onboard GPU)</h2>\n",
       "    <p>1091\n",
       " frames processed in 93.201291\n",
       " seconds</p>\n",
       "    <video alt=\"\" controls autoplay height=\"480\"><source src=\"results/output_44108.c003.mp4\" type=\"video/mp4\" /></video>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videoHTML('IEI Intel GPU (Intel Core + Onboard GPU)', \n",
    "          ['results/output_'+job_id_gpu_fp16[0]+'.mp4'],\n",
    "          '../results/stats_'+job_id_gpu_fp16[0]+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>IEI Tank Core (Intel VPU)</h2>\n",
       "    <p>1091\n",
       " frames processed in 96.017279\n",
       " seconds</p>\n",
       "    <video alt=\"\" controls autoplay height=\"480\"><source src=\"results/output_44112.c003.mp4\" type=\"video/mp4\" /></video>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videoHTML('IEI Tank Core (Intel VPU)',\n",
    "          ['results/output_'+job_id_hddl_fp16[0]+'.mp4'],\n",
    "          '../results/stats_'+job_id_hddl_fp16[0]+'.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>IEI Tank + IEI Mustang-F100-A10 (Intel® Arria® 10 FPGA)</h2>\n",
       "    <p>1091\n",
       " frames processed in 93.602076\n",
       " seconds</p>\n",
       "    <video alt=\"\" controls autoplay height=\"480\"><source src=\"results/output_44113.c003.mp4\" type=\"video/mp4\" /></video>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "videoHTML('IEI Tank + IEI Mustang-F100-A10 (Intel® Arria® 10 FPGA)',\n",
    "          ['results/output_'+job_id_fpga_16[0]+'.mp4'],\n",
    "          '../results/stats_'+job_id_fpga_16[0]+'.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Assess Performance\n",
    "\n",
    "The running time of each inference task is recorded in `results/*/stats.txt`, where the subdirectory name corresponds to the architecture of the target edge compute node. Run the cell below to plot the results of all jobs side-by-side. Lower values mean better performance. Keep in mind that some architectures are optimized for the highest performance, others for low power or other metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/u26213/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 3296, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-35-d1e55e6d8ab1>\", line 4, in <module>\n",
      "    ('gpu_fp16',' Intel Core\\ni5-6500TE\\nGPU-16'),\n",
      "TypeError: 'tuple' object is not callable\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/u26213/.local/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/u26213/.local/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/u26213/.local/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/u26213/.local/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 1453, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 1410, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 672, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 701, in getmodule\n",
      "    file = getabsfile(object, _filename)\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 685, in getabsfile\n",
      "    return os.path.normcase(os.path.abspath(_filename))\n",
      "  File \"/usr/lib/python3.5/posixpath.py\", line 361, in abspath\n",
      "    cwd = os.getcwd()\n",
      "FileNotFoundError: [Errno 2] No such file or directory\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "arch_list = [('core', 'Intel Core\\ni5-6500TE CPU'),\n",
    "             ('gpu', 'Intel Core\\nE3-1268L v5 GPU-32'),\n",
    "             ('xeon', 'Intel xeon\\ntank-870:e3-1268l-v5')\n",
    "             ('gpu_fp16', 'Intel Core\\ni5-6500TE\\nGPU-16'),\n",
    "            ('hddl_fp16', 'Intel VPU\\nMustang-V100-MX8'),\n",
    "            ('fpga_16', 'Intel FPGA\\nMustang-F100-A10')]\n",
    "\n",
    "stats_list = []\n",
    "for arch, a_name in arch_list:\n",
    "    if 'job_id_'+arch in vars():\n",
    "        #stats_list.append(('../results/{arch}/stats.txt'.format(arch=arch), a_name))\n",
    "        stats_list.append(('../results/stats_'+vars()['job_id_'+arch][0]+'.txt', a_name))\n",
    "    else:\n",
    "        stats_list.append(('placeholder'+arch, a_name))\n",
    "\n",
    "summaryPlot(stats_list, 'Architecture', 'Time, seconds', 'Inference Engine Processing Time', 'time' )\n",
    "summaryPlot(stats_list, 'Architecture', 'Frames per second', 'Inference Engine FPS', 'fps' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Ubuntu)",
   "language": "python",
   "name": "c003-python_3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
